{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06f64d6",
   "metadata": {},
   "source": [
    "# Introduction to NLP in Python\n",
    "## Quest 1: NLP Basics for Text Preprocessing\n",
    "\n",
    "### Tokenization\n",
    "\n",
    "Tokenizers divide strings into lists of substrings. After installing the nltk library, let's import the library along with these two built-in methods, *sent_tokenize* and *word_tokenize*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f673677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\seenu nahak\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\seenu nahak\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\seenu nahak\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\seenu nahak\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\seenu nahak\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\seenu nahak\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Seenu\n",
      "[nltk_data]     Nahak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6b267",
   "metadata": {},
   "source": [
    "1. `sent_tokenize`\n",
    "\n",
    "The first method, `sent_tokenize`, splits the given text into sentences. This is useful especially if you are dealing with bigger chunks of text with longer sentences.\n",
    "\n",
    "We will make use of the following sample paragraph about NLP in the healthcare industry. Run the cell below to check out the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d6c0ebb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP drives computer programs that translate text from one language to another, respond to spoken commands, and summarize large volumes of text rapidly—even in real time.',\n",
       " 'There’s a good chance you’ve interacted with NLP in the form of voice-operated GPS systems, digital assistants, speech-to-text dictation software, customer service chatbots, and other consumer conveniences.',\n",
       " 'But NLP also plays a growing role in enterprise solutions that help streamline business operations, increase employee productivity, and simplify mission-critical business processes.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'NLP drives computer programs that translate text from one language to another, respond to spoken commands, and summarize large volumes of text rapidly—even in real time. There’s a good chance you’ve interacted with NLP in the form of voice-operated GPS systems, digital assistants, speech-to-text dictation software, customer service chatbots, and other consumer conveniences. But NLP also plays a growing role in enterprise solutions that help streamline business operations, increase employee productivity, and simplify mission-critical business processes.'\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650cb69",
   "metadata": {},
   "source": [
    "If you encounter the \"Resource punkt not found\" error when running the above cell, you can run the following command `nltk.download('punkt')`\n",
    "<br/><br/>\n",
    "\n",
    "2. `word_tokenize`\n",
    "\n",
    "Likewise, the `word_tokenize` method tokenizes each individual word in the paragraph. Run the cell below to compare the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b00bd69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP',\n",
       " 'drives',\n",
       " 'computer',\n",
       " 'programs',\n",
       " 'that',\n",
       " 'translate',\n",
       " 'text',\n",
       " 'from',\n",
       " 'one',\n",
       " 'language',\n",
       " 'to',\n",
       " 'another',\n",
       " ',',\n",
       " 'respond',\n",
       " 'to',\n",
       " 'spoken',\n",
       " 'commands',\n",
       " ',',\n",
       " 'and',\n",
       " 'summarize',\n",
       " 'large',\n",
       " 'volumes',\n",
       " 'of',\n",
       " 'text',\n",
       " 'rapidly—even',\n",
       " 'in',\n",
       " 'real',\n",
       " 'time',\n",
       " '.',\n",
       " 'There',\n",
       " '’',\n",
       " 's',\n",
       " 'a',\n",
       " 'good',\n",
       " 'chance',\n",
       " 'you',\n",
       " '’',\n",
       " 've',\n",
       " 'interacted',\n",
       " 'with',\n",
       " 'NLP',\n",
       " 'in',\n",
       " 'the',\n",
       " 'form',\n",
       " 'of',\n",
       " 'voice-operated',\n",
       " 'GPS',\n",
       " 'systems',\n",
       " ',',\n",
       " 'digital',\n",
       " 'assistants',\n",
       " ',',\n",
       " 'speech-to-text',\n",
       " 'dictation',\n",
       " 'software',\n",
       " ',',\n",
       " 'customer',\n",
       " 'service',\n",
       " 'chatbots',\n",
       " ',',\n",
       " 'and',\n",
       " 'other',\n",
       " 'consumer',\n",
       " 'conveniences',\n",
       " '.',\n",
       " 'But',\n",
       " 'NLP',\n",
       " 'also',\n",
       " 'plays',\n",
       " 'a',\n",
       " 'growing',\n",
       " 'role',\n",
       " 'in',\n",
       " 'enterprise',\n",
       " 'solutions',\n",
       " 'that',\n",
       " 'help',\n",
       " 'streamline',\n",
       " 'business',\n",
       " 'operations',\n",
       " ',',\n",
       " 'increase',\n",
       " 'employee',\n",
       " 'productivity',\n",
       " ',',\n",
       " 'and',\n",
       " 'simplify',\n",
       " 'mission-critical',\n",
       " 'business',\n",
       " 'processes',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5908050b",
   "metadata": {},
   "source": [
    "Additionally, feel free to experiment with different sentences and pieces of text and passing them through each tokenizer. \n",
    "\n",
    "There are many more types of tokenizers in the nltk library itself, catered to producing various tokens based on the type of data that is needed. You can learn more about tokenizers from the nltk documentation [here](https://www.nltk.org/api/nltk.tokenize.html).\n",
    "\n",
    "Return back to the StackUp platform, where we will continue on with the quest.\n",
    "\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a894c1a",
   "metadata": {},
   "source": [
    "### Removing stop words\n",
    "\n",
    "Stop words are the common words which don't really add much meaning to the text. Some stop words in English includes conjunctions such as for, and, but, or, yet, so, and articles such as a, an, the.\n",
    "\n",
    "NLTK has pre-defined stop words for English. Let's go ahead and import it by running in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577c7d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Seenu\n",
      "[nltk_data]     Nahak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b226b1dd",
   "metadata": {},
   "source": [
    "The list stopwords now contains the NLTK predefined stop words. Using the tokenized text from earlier, let's remove the stop words and return the remaining tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e9e922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'drives', 'computer', 'programs', 'translate', 'text', 'one', 'language', 'another', ',', 'respond', 'spoken', 'commands', ',', 'summarize', 'large', 'volumes', 'text', 'rapidly—even', 'real', 'time', '.', 'There', '’', 'good', 'chance', '’', 'interacted', 'NLP', 'form', 'voice-operated', 'GPS', 'systems', ',', 'digital', 'assistants', ',', 'speech-to-text', 'dictation', 'software', ',', 'customer', 'service', 'chatbots', ',', 'consumer', 'conveniences', '.', 'But', 'NLP', 'also', 'plays', 'growing', 'role', 'enterprise', 'solutions', 'help', 'streamline', 'business', 'operations', ',', 'increase', 'employee', 'productivity', ',', 'simplify', 'mission-critical', 'business', 'processes', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "tokens_no_stopwords = [i for i in tokens if i not in stopwords]\n",
    "print(tokens_no_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484e6cc",
   "metadata": {},
   "source": [
    "Now, lets head back to the StackUp platform, where we cover the third preprocessing technique in this quest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba3c19d",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### Stemming and Lemmatization\n",
    "\n",
    "Here, we will experiment using the PorterStemmer and WordNetLemmatizer. Recall from the quest that stemming removes the suffix from the word while lemmatization takes into account the context and what the word means in the sentence.\n",
    "\n",
    "Play along with different words to compare the outputs produced by a stemmer and a lemmatizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ccbc57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Seenu\n",
      "[nltk_data]     Nahak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# run these lines if they have yet to be downloaded.\n",
    "# once downloaded, you can comment out the lines.\n",
    "nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa877b4",
   "metadata": {},
   "source": [
    "Let's test both methods on various pluralised words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b16dff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming results:  ['appl', 'octopus', 'categori', 'criteria', 'tomato', 'matric', 'hypothes', 'radii', 'alga', 'cacti']\n",
      "Lemmatization results;  ['apple', 'octopus', 'category', 'criterion', 'tomato', 'matrix', 'hypothesis', 'radius', 'algae', 'cactus']\n"
     ]
    }
   ],
   "source": [
    "plurals = ['apples', 'octopuses', 'categories', 'criteria', 'tomatoes', 'matrices', 'hypotheses', 'radii', 'algae', 'cacti']\n",
    "\n",
    "plurals_stem = [stemmer.stem(plural) for plural in plurals]\n",
    "plurals_lemma = [lemma.lemmatize(plural) for plural in plurals]\n",
    "\n",
    "print(\"Stemming results: \", plurals_stem)\n",
    "print(\"Lemmatization results; \", plurals_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403f0a6a",
   "metadata": {},
   "source": [
    "Compare the results produced above! The lemmatizer is more accurate when it comes to getting the root word of more complex plurals, however it is important to note that in the case of a large dataset, stemming comes in handy where performance is an issue. \n",
    "\n",
    "And that sums up the 3 techniques for text preprocessing in NLP! **Return back to the StackUp platform,** where we wrap up the quest and prepare the deliverables for submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "021a4819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP drives computer programs that translate text from one language to another, respond to spoken commands, and summarize large volumes of text rapidly—even in real time. There’s a good chance you’ve interacted with NLP in the form of voice-operated GPS systems, digital assistants, speech-to-text dictation software, customer service chatbots, and other consumer conveniences. But NLP also plays a growing role in enterprise solutions that help streamline business operations, increase employee productivity, and simplify mission-critical business processes. \n",
      "\n",
      "['NLP drives computer programs that translate text from one language to another, respond to spoken commands, and summarize large volumes of text rapidly—even in real time.', 'There’s a good chance you’ve interacted with NLP in the form of voice-operated GPS systems, digital assistants, speech-to-text dictation software, customer service chatbots, and other consumer conveniences.', 'But NLP also plays a growing role in enterprise solutions that help streamline business operations, increase employee productivity, and simplify mission-critical business processes.'] \n",
      "\n",
      "['NLP', 'drives', 'computer', 'programs', 'that', 'translate', 'text', 'from', 'one', 'language', 'to', 'another', ',', 'respond', 'to', 'spoken', 'commands', ',', 'and', 'summarize', 'large', 'volumes', 'of', 'text', 'rapidly—even', 'in', 'real', 'time', '.', 'There', '’', 's', 'a', 'good', 'chance', 'you', '’', 've', 'interacted', 'with', 'NLP', 'in', 'the', 'form', 'of', 'voice-operated', 'GPS', 'systems', ',', 'digital', 'assistants', ',', 'speech-to-text', 'dictation', 'software', ',', 'customer', 'service', 'chatbots', ',', 'and', 'other', 'consumer', 'conveniences', '.', 'But', 'NLP', 'also', 'plays', 'a', 'growing', 'role', 'in', 'enterprise', 'solutions', 'that', 'help', 'streamline', 'business', 'operations', ',', 'increase', 'employee', 'productivity', ',', 'and', 'simplify', 'mission-critical', 'business', 'processes', '.'] \n",
      "\n",
      "['NLP', 'drives', 'computer', 'programs', 'translate', 'text', 'one', 'language', 'another', ',', 'respond', 'spoken', 'commands', ',', 'summarize', 'large', 'volumes', 'text', 'rapidly—even', 'real', 'time', '.', 'There', '’', 'good', 'chance', '’', 'interacted', 'NLP', 'form', 'voice-operated', 'GPS', 'systems', ',', 'digital', 'assistants', ',', 'speech-to-text', 'dictation', 'software', ',', 'customer', 'service', 'chatbots', ',', 'consumer', 'conveniences', '.', 'But', 'NLP', 'also', 'plays', 'growing', 'role', 'enterprise', 'solutions', 'help', 'streamline', 'business', 'operations', ',', 'increase', 'employee', 'productivity', ',', 'simplify', 'mission-critical', 'business', 'processes', '.'] \n",
      "\n",
      "Stemming results ['nlp', 'drive', 'comput', 'program', 'translat', 'text', 'one', 'languag', 'anoth', ',', 'respond', 'spoken', 'command', ',', 'summar', 'larg', 'volum', 'text', 'rapidly—even', 'real', 'time', '.', 'there', '’', 'good', 'chanc', '’', 'interact', 'nlp', 'form', 'voice-oper', 'gp', 'system', ',', 'digit', 'assist', ',', 'speech-to-text', 'dictat', 'softwar', ',', 'custom', 'servic', 'chatbot', ',', 'consum', 'conveni', '.', 'but', 'nlp', 'also', 'play', 'grow', 'role', 'enterpris', 'solut', 'help', 'streamlin', 'busi', 'oper', ',', 'increas', 'employe', 'product', ',', 'simplifi', 'mission-crit', 'busi', 'process', '.'] \n",
      "\n",
      "Lemmatization results;  ['NLP', 'drive', 'computer', 'program', 'translate', 'text', 'one', 'language', 'another', ',', 'respond', 'spoken', 'command', ',', 'summarize', 'large', 'volume', 'text', 'rapidly—even', 'real', 'time', '.', 'There', '’', 'good', 'chance', '’', 'interacted', 'NLP', 'form', 'voice-operated', 'GPS', 'system', ',', 'digital', 'assistant', ',', 'speech-to-text', 'dictation', 'software', ',', 'customer', 'service', 'chatbots', ',', 'consumer', 'convenience', '.', 'But', 'NLP', 'also', 'play', 'growing', 'role', 'enterprise', 'solution', 'help', 'streamline', 'business', 'operation', ',', 'increase', 'employee', 'productivity', ',', 'simplify', 'mission-critical', 'business', 'process', '.']\n"
     ]
    }
   ],
   "source": [
    "print(text, \"\\n\")\n",
    "print(sent_tokenize(text), \"\\n\")\n",
    "print(word_tokenize(text), \"\\n\")\n",
    "print(tokens_no_stopwords, \"\\n\")\n",
    "print(\"Stemming results\", [stemmer.stem(i) for i in tokens_no_stopwords], \"\\n\")\n",
    "print(\"Lemmatization results; \", [lemma.lemmatize(i) for i in tokens_no_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99044123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f9d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecdce2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0141c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892bfd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc78111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
